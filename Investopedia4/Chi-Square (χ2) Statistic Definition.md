---
alias: [Chi-Square (χ2) Statistic]
created: 2021-03-02T18:51:36 (UTC +11:00)
tags: [Chi-Square (χ2) Statistic Definition, Chi-Square (χ2) Statistic Definition]
source: https://www.investopedia.com/terms/c/chi-square-statistic.asp
author: Adam Hayes
---

# [[Chi-Square (χ2) Statistic Definition]]

> ## Excerpt
> A chi-square (χ2) statistic is a test that measures how expectations compare to actual observed data (or model results).

---

[[Chi-Square (χ2) Statistic Definition]]
## What Is a Chi-Square Statistic?

A chi-square (_χ_2) statistic is a test that measures how a model compares to actual observed data. The data used in calculating a chi-square [[statistic]](https://www.investopedia.com/terms/s/statistics.asp) must be random, raw, [[mutually exclusive]](https://www.investopedia.com/terms/m/mutuallyexclusive.asp), drawn from independent variables, and drawn from a large enough sample. For example, the results of tossing a fair coin meet these criteria.

Chi-square tests are often used in [[hypothesis testing]](https://www.investopedia.com/terms/h/hypothesistesting.asp). The chi-square statistic compares the size any discrepancies between the expected results and the actual results, given the size of the sample and the number of variables in the relationship. For these tests, [[degrees of freedom]](https://www.investopedia.com/terms/d/degrees-of-freedom.asp) are utilized to determine if a certain [null hypothesis](https://www.investopedia.com/terms/n/null_hypothesis.asp) can be rejected based on the total number of variables and samples within the experiment. As with any statistic, the larger the sample size, the more reliable the results.

### Key Takeaways

-   A chi-square (_χ_2) statistic is a measure of the difference between the observed and expected frequencies of the outcomes of a set of events or variables.
-   _χ_2 depends on the size of the difference between actual and observed values, the degrees of freedom, and the samples size.
-   _χ_2 can be used to test whether two variables are related or independent from one another or to test the goodness-of-fit between an observed distribution and a theoretical distribution of frequencies.

## The Formula for Chi-Square Is

χc2\=∑(Oi−Ei)2Eiwhere:c\=Degrees of freedomO\=Observed value(s)E\=Expected value(s)\\begin{aligned}&\\chi^2\_c = \\sum \\frac{(O\_i - E\_i)^2}{E\_i} \\\\&\\textbf{where:}\\\\&c=\\text{Degrees of freedom}\\\\&O=\\text{Observed value(s)}\\\\&E=\\text{Expected value(s)}\\end{aligned}

## What Does a Chi-Square Statistic Tell You?

There are two main kinds of chi-square tests: the test of independence, which asks a question of relationship, such as, "Is there a relationship between student sex and course choice?"; and the [goodness-of-fit test](https://www.investopedia.com/terms/g/goodness-of-fit.asp), which asks something like "How well does the coin in my hand match a theoretically fair coin?"

### Independence

When considering student sex and course choice, a _χ_2 test for independence could be used. To do this test, the researcher would collect data on the two chosen variables (sex and courses picked) and then compare the frequencies at which male and female students select among the offered classes using the formula given above and a _χ_2 statistical table.

If there is no relationship between sex and course selection (that is, if they are independent), then the actual frequencies at which male and female students select each offered course should be expected to be approximately equal, or conversely, the proportion of male and female students in any selected course should be approximately equal to the proportion of male and female students in the sample. A _χ_2 test for independence can tell us how likely it is that random chance can explain any observed difference between the actual frequencies in the data and these theoretical expectations.

### Goodness-of-Fit

_χ_2 provides a way to test how well a sample of data matches the (known or assumed) characteristics of the larger population that the sample is intended to represent. If the sample data do not fit the expected properties of the population that we are interested in, then we would not want to use this sample to draw conclusions about the larger population.

For example consider an imaginary coin with exactly 50/50 chance of landing heads or tails and a real coin that you toss 100 times. If this real coin has an is fair, then it [[Will|will]] also have an equal probability of landing on either side, and the expected result of tossing the coin 100 times is that heads will come up 50 times and tails will come up 50 times. In this case, _χ_2 can tell us how well the actual results of 100 coin flips compare to the theoretical model that a fair coin will give 50/50 results. The actual toss could come up 50/50, or 60/40, or even 90/10. The farther away the actual results of the 100 tosses is from 50/50, the less good the fit of this set of tosses is to the theoretical expectation of 50/50 and the more likely we might conclude that this coin is not actually a fair coin.
